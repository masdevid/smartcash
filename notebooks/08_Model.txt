# ================= [MODEL UTILITIES] =================
# Cell 8: Setup Utilitas Model
# Import modul-modul esensial
from smartcash.smartcash.models.backbones.cspdarknet import CSPDarknet
from smartcash.smartcash.models.backbones.efficientnet import EfficientNetBackbone
from smartcash.smartcash.models.yolov5_model import YOLOv5Model
from smartcash.smartcash.handlers.data_handler import DataHandler
from torch.utils.data import DataLoader
from smartcash.smartcash.utils.early_stopping import EarlyStopping
from smartcash.smartcash.utils.model_checkpoint import StatelessCheckpointSaver

class ModelManager:
    """Pengelola model SmartCash dengan dukungan backbone berbeda"""
    
    def __init__(self, config):
        self.config = config
        self.logger = SmartCashLogger("model_manager")
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.num_classes = 7  # Default untuk single layer banknote
        
        # Setup classes berdasarkan mode deteksi
        if config.get('detection_mode') == 'multi':
            self.num_classes = 17  # Total kelas untuk multi layer
        
        self.logger.info(f"üîÑ Inisialisasi model dengan {self.num_classes} kelas")
        
    def create_model(self, backbone_type=None):
        """Buat model YOLOv5 dengan backbone tertentu"""
        backbone = backbone_type or self.config.get('model', {}).get('backbone', 'efficientnet')
        
        layers = self.config.get('layers', ['banknote'])
        
        self.logger.info(f"üèóÔ∏è Membuat model YOLOv5 dengan backbone {backbone} dan layers {layers}")
        
        model = YOLOv5Model(
            num_classes=self.num_classes,
            backbone_type=backbone,
            pretrained=True,
            detection_layers=layers
        )
        
        # Pindahkan model ke device yang tersedia
        model = model.to(self.device)
        
        return model

    def get_optimizer(self, model, lr=None):
        """Dapatkan optimizer untuk model"""
        learning_rate = lr or self.config.get('training', {}).get('learning_rate', 0.001)
        
        self.logger.info(f"üîß Membuat optimizer dengan learning rate {learning_rate}")
        
        return torch.optim.Adam(
            model.parameters(),
            lr=learning_rate,
            weight_decay=self.config.get('training', {}).get('weight_decay', 0.0005)
        )
    
    def save_checkpoint(self, model, epoch, loss, is_best=False):
        """Simpan checkpoint model"""
        checkpoint_dir = self.config.get('output_dir', 'runs/train') + '/weights'
        os.makedirs(checkpoint_dir, exist_ok=True)
        
        return StatelessCheckpointSaver.save_checkpoint(
            model=model,
            config=self.config,
            epoch=epoch,
            loss=loss,
            checkpoint_dir=checkpoint_dir,
            is_best=is_best,
            log_fn=self.logger.info
        )