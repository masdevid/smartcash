# Cell 9.5: Research Evaluation - Evaluasi perbandingan skenario penelitian

import os
import torch
import gc
import numpy as np
import ipywidgets as widgets
from IPython.display import display, clear_output, HTML
import pickle
from pathlib import Path
import pandas as pd
from contextlib import contextmanager
import yaml
import time

# Pastikan path diatur dengan benar
import sys
if os.getcwd() not in sys.path:
    sys.path.append(os.getcwd())

# Context manager untuk manajemen memori
@contextmanager
def memory_manager():
    """Context manager untuk optimasi penggunaan memori."""
    try:
        yield
    finally:
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

# ===== 1. LOAD NECESSARY MODULES =====
try:
    # Import modul-modul penelitian
    from smartcash.utils.logger import get_logger
    from smartcash.handlers.research_scenario_handler import ResearchScenarioHandler
    from smartcash.handlers.evaluation_handler import EvaluationHandler
    
    # Coba import visualizer
    try:
        from smartcash.utils.model_visualizer import ModelVisualizer
        visualizer = ModelVisualizer()
        has_visualizer = True
    except ImportError:
        has_visualizer = False
        
    try:
        from smartcash.utils.visualization import ResultVisualizer, plot_radar_chart
        result_visualizer = ResultVisualizer()
        has_result_visualizer = True
    except ImportError:
        has_result_visualizer = False
    
    logger = get_logger("research_evaluation", log_to_console=True)
    logger.info("‚úÖ Modul penelitian berhasil diimport")
    
    # Muat konfigurasi
    try:
        with open('config.pkl', 'rb') as f:
            config = pickle.load(f)
    except FileNotFoundError:
        # Coba load dari file yaml
        try:
            with open('configs/base_config.yaml', 'r') as f:
                config = yaml.safe_load(f)
        except FileNotFoundError:
            logger.warning("‚ö†Ô∏è Tidak dapat memuat konfigurasi")
            config = {}
except Exception as e:
    print(f"‚ùå Error saat import modul penelitian: {str(e)}")
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging
    config = {}
    has_visualizer = False
    has_result_visualizer = False

# ===== 2. RESEARCH SCENARIO DEFINITIONS =====
# Definisikan skenario penelitian yang harus dievaluasi
RESEARCH_SCENARIOS = [
    {
        'name': 'Skenario-1',
        'description': 'CSPDarknet - Posisi Bervariasi',
        'backbone': 'cspdarknet',
        'conditions': 'position',
        'test_data': 'data/test_position_varied',
    },
    {
        'name': 'Skenario-2',
        'description': 'CSPDarknet - Pencahayaan Bervariasi',
        'backbone': 'cspdarknet',
        'conditions': 'lighting',
        'test_data': 'data/test_lighting_varied',
    },
    {
        'name': 'Skenario-3',
        'description': 'EfficientNet-B4 - Posisi Bervariasi',
        'backbone': 'efficientnet',
        'conditions': 'position',
        'test_data': 'data/test_position_varied',
    },
    {
        'name': 'Skenario-4',
        'description': 'EfficientNet-B4 - Pencahayaan Bervariasi',
        'backbone': 'efficientnet',
        'conditions': 'lighting',
        'test_data': 'data/test_lighting_varied',
    }
]

# ===== 3. RESEARCH EVALUATION FUNCTIONS =====
def run_research_evaluation(scenarios=None, visualize=True):
    """
    Jalankan evaluasi skenario penelitian.
    
    Args:
        scenarios: List skenario yang akan dievaluasi (jika None, evaluasi semua)
        visualize: Jika True, visualisasikan hasil evaluasi
        
    Returns:
        DataFrame hasil evaluasi
    """
    try:
        with memory_manager():
            # Inisialisasi handler penelitian
            research_handler = ResearchScenarioHandler(
                config=config,
                logger=logger
            )
            
            # Filter skenario jika perlu
            if scenarios is None:
                scenarios = RESEARCH_SCENARIOS
            elif isinstance(scenarios, str):
                # Jika single scenario name passed
                scenarios = [s for s in RESEARCH_SCENARIOS if s['name'] == scenarios]
            
            # Siapkan storage untuk hasil
            results_data = []
            
            # Jalankan evaluasi untuk setiap skenario
            for scenario in scenarios:
                try:
                    logger.info(f"üî¨ Evaluasi skenario: {scenario['name']} - {scenario['description']}")
                    
                    # Get model path untuk skenario ini
                    # Note: Ini harus diubah sesuai konvensi penamaan checkpoint di project
                    model_path = f"runs/train/weights/{scenario['backbone']}_{scenario['conditions']}_best.pth"
                    
                    # Cek keberadaan model
                    if not os.path.exists(model_path):
                        # Cari model dengan pola serupa jika tidak ada
                        potential_models = list(Path('runs/train/weights').glob(f"*{scenario['backbone']}*{scenario['conditions']}*best*.pth"))
                        if potential_models:
                            model_path = str(potential_models[0])
                            logger.info(f"üîç Menggunakan alternatif model path: {model_path}")
                        else:
                            logger.warning(f"‚ö†Ô∏è Model tidak ditemukan untuk skenario {scenario['name']}")
                            # Dummy result untuk skenario yang tidak dapat dievaluasi
                            results_data.append({
                                'Skenario': scenario['name'],
                                'Deskripsi': scenario['description'],
                                'Backbone': scenario['backbone'],
                                'Kondisi': scenario['conditions'],
                                'Status': 'Model tidak ditemukan',
                            })
                            continue
                    
                    # Evaluasi model untuk skenario ini
                    evaluation_result = research_handler.evaluate_scenario(
                        scenario['name'],
                        model_path,
                        scenario['test_data']
                    )
                    
                    # Ambil metrik dari hasil evaluasi
                    metrics = evaluation_result.get('metrics', {})
                    
                    # Simpan hasil evaluasi
                    results_data.append({
                        'Skenario': scenario['name'],
                        'Deskripsi': scenario['description'],
                        'Backbone': scenario['backbone'],
                        'Kondisi': scenario['conditions'],
                        'Status': 'Sukses',
                        'Akurasi': metrics.get('accuracy', 0) * 100,
                        'Precision': metrics.get('precision', 0) * 100,
                        'Recall': metrics.get('recall', 0) * 100,
                        'F1-Score': metrics.get('f1', 0) * 100,
                        'mAP': metrics.get('mAP', 0) * 100,
                        'Inference Time (ms)': metrics.get('inference_time', 0)
                    })
                    
                except Exception as e:
                    logger.error(f"‚ùå Error pada skenario {scenario['name']}: {str(e)}")
                    results_data.append({
                        'Skenario': scenario['name'],
                        'Deskripsi': scenario['description'],
                        'Backbone': scenario['backbone'],
                        'Kondisi': scenario['conditions'],
                        'Status': f'Error: {str(e)}',
                    })
            
            # Convert ke DataFrame
            results_df = pd.DataFrame(results_data)
            
            # Buat direktori jika belum ada
            os.makedirs('runs/evaluation', exist_ok=True)
            
            # Simpan hasil untuk referensi future
            results_df.to_csv('runs/evaluation/research_results.csv', index=False)
            
            # Visualisasikan hasil jika diminta
            if visualize and len(results_data) > 0:
                visualize_research_results(results_df)
            
            return results_df
    
    except Exception as e:
        logger.error(f"‚ùå Error saat evaluasi penelitian: {str(e)}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()

def visualize_research_results(results_df):
    """
    Visualisasikan hasil evaluasi skenario penelitian.
    
    Args:
        results_df: DataFrame hasil evaluasi dari run_research_evaluation()
    """
    if results_df.empty:
        logger.warning("‚ö†Ô∏è Tidak ada hasil penelitian untuk divisualisasikan")
        return
    
    try:
        # Filter hanya skenario yang berhasil
        success_results = results_df[results_df['Status'] == 'Sukses'].copy()
        
        if success_results.empty:
            logger.warning("‚ö†Ô∏è Tidak ada skenario yang berhasil dievaluasi")
            display(results_df)
            return
        
        # Cek apakah visualizer tersedia untuk hasil penelitian
        if has_visualizer and hasattr(visualizer, 'visualize_research_comparison'):
            visualizer.visualize_research_comparison(success_results)
            return
        
        # Tampilkan tabel utama hasil evaluasi
        display(HTML("<h3>üìä Hasil Evaluasi Skenario Penelitian</h3>"))
        
        # Style DataFrame untuk tampilan yang lebih baik
        styled_df = success_results.style.format({
            'Akurasi': '{:.2f}%',
            'Precision': '{:.2f}%',
            'Recall': '{:.2f}%',
            'F1-Score': '{:.2f}%',
            'mAP': '{:.2f}%',
            'Inference Time (ms)': '{:.2f}'
        })
        
        # Highlight skenario terbaik untuk setiap metrik
        styled_df = styled_df.highlight_max(
            subset=['Akurasi', 'Precision', 'Recall', 'F1-Score', 'mAP'],
            color='lightgreen'
        )
        
        # Highlight skenario tercepat (inference time paling rendah)
        styled_df = styled_df.highlight_min(
            subset=['Inference Time (ms)'],
            color='lightgreen'
        )
        
        # Tampilkan tabel dengan format
        display(styled_df)
        
        # Visualisasikan perbandingan metrik antar skenario menggunakan fungsi yang tersedia
        if has_visualizer or has_result_visualizer:
            if has_visualizer and hasattr(visualizer, 'plot_scenario_comparison'):
                # Gunakan fungsi plot dari ModelVisualizer
                visualizer.plot_scenario_comparison(success_results)
            elif has_result_visualizer and hasattr(result_visualizer, 'plot_research_comparison'):
                # Gunakan fungsi plot dari ResultVisualizer
                result_visualizer.plot_research_comparison(success_results)
            elif 'plot_radar_chart' in globals():
                # Gunakan fungsi plot_radar_chart jika tersedia sebagai fungsi standalone
                plot_research_comparison_fallback(success_results)
            else:
                # Fallback ke custom visualization
                plot_research_comparison_fallback(success_results)
        else:
            # Fallback ke custom visualization
            plot_research_comparison_fallback(success_results)
        
        # Tampilkan analisis dan rekomendasi
        display(HTML("<h3>üîç Analisis & Kesimpulan</h3>"))
        
        # Temukan skenario terbaik untuk setiap metrik
        best_accuracy = success_results.loc[success_results['Akurasi'].idxmax()]
        best_f1 = success_results.loc[success_results['F1-Score'].idxmax()]
        best_map = success_results.loc[success_results['mAP'].idxmax()]
        fastest = success_results.loc[success_results['Inference Time (ms)'].idxmin()]
        
        print(f"üèÜ Skenario dengan akurasi tertinggi: {best_accuracy['Skenario']} ({best_accuracy['Akurasi']:.2f}%)")
        print(f"üèÜ Skenario dengan F1-Score tertinggi: {best_f1['Skenario']} ({best_f1['F1-Score']:.2f}%)")
        print(f"üèÜ Skenario dengan mAP tertinggi: {best_map['Skenario']} ({best_map['mAP']:.2f}%)")
        print(f"‚ö° Skenario tercepat: {fastest['Skenario']} ({fastest['Inference Time (ms)']:.2f}ms, {1000/fastest['Inference Time (ms)']:.1f} FPS)")
        
        # Analisis backbone
        efficientnet_results = success_results[success_results['Backbone'] == 'efficientnet']
        cspdarknet_results = success_results[success_results['Backbone'] == 'cspdarknet']
        
        if not efficientnet_results.empty and not cspdarknet_results.empty:
            # Hitung rata-rata metrik per backbone
            efficientnet_avg = efficientnet_results[['Akurasi', 'Precision', 'Recall', 'F1-Score', 'mAP', 'Inference Time (ms)']].mean()
            cspdarknet_avg = cspdarknet_results[['Akurasi', 'Precision', 'Recall', 'F1-Score', 'mAP', 'Inference Time (ms)']].mean()
            
            print("\nüìà Perbandingan Backbone:")
            print(f"‚Ä¢ EfficientNet-B4 - Akurasi rata-rata: {efficientnet_avg['Akurasi']:.2f}%, Inference time: {efficientnet_avg['Inference Time (ms)']:.2f}ms")
            print(f"‚Ä¢ CSPDarknet - Akurasi rata-rata: {cspdarknet_avg['Akurasi']:.2f}%, Inference time: {cspdarknet_avg['Inference Time (ms)']:.2f}ms")
            
            # Buat rekomendasi
            accuracy_diff = efficientnet_avg['Akurasi'] - cspdarknet_avg['Akurasi']
            speed_diff = cspdarknet_avg['Inference Time (ms)'] - efficientnet_avg['Inference Time (ms)']
            
            if accuracy_diff > 0 and speed_diff > 0:
                print("\nüí° Rekomendasi: EfficientNet-B4 lebih unggul secara keseluruhan, dengan akurasi lebih tinggi dan inferensi lebih cepat.")
            elif accuracy_diff > 0:
                print(f"\nüí° Rekomendasi: EfficientNet-B4 memberikan akurasi lebih tinggi (+{accuracy_diff:.2f}%), namun CSPDarknet lebih cepat (+{-speed_diff:.2f}ms).")
                if accuracy_diff > abs(speed_diff):
                    print("     üëâ Untuk aplikasi yang mengutamakan akurasi, gunakan EfficientNet-B4.")
                else:
                    print("     üëâ Pilih backbone berdasarkan kebutuhan: akurasi (EfficientNet-B4) atau kecepatan (CSPDarknet).")
            elif speed_diff > 0:
                print(f"\nüí° Rekomendasi: CSPDarknet memberikan akurasi lebih tinggi (+{-accuracy_diff:.2f}%), namun EfficientNet-B4 lebih cepat (+{speed_diff:.2f}ms).")
                if abs(accuracy_diff) > speed_diff:
                    print("     üëâ Untuk aplikasi yang mengutamakan akurasi, gunakan CSPDarknet.")
                else:
                    print("     üëâ Pilih backbone berdasarkan kebutuhan: akurasi (CSPDarknet) atau kecepatan (EfficientNet-B4).")
            else:
                print("\nüí° Rekomendasi: CSPDarknet lebih unggul secara keseluruhan, dengan akurasi lebih tinggi dan inferensi lebih cepat.")
        
    except Exception as e:
        logger.error(f"‚ùå Error saat visualisasi hasil penelitian: {str(e)}")
        import traceback
        traceback.print_exc()

def plot_research_comparison_fallback(success_results):
    """
    Visualisasi fallback untuk perbandingan skenario penelitian.
    Fungsi ini hanya digunakan jika tidak ada visualizer yang tersedia.
    
    Args:
        success_results: DataFrame dengan hasil evaluasi yang berhasil
    """
    try:
        import matplotlib.pyplot as plt
        import seaborn as sns
        
        # Visualisasikan perbandingan metrik antar skenario
        plt.figure(figsize=(15, 10))
        
        # Plot Metrik Akurasi (Heatmap) - Subplot 1
        plt.subplot(2, 2, 1)
        
        # Set metrik untuk heatmap
        metrics_for_heatmap = success_results.set_index('Skenario')[
            ['Akurasi', 'Precision', 'Recall', 'F1-Score', 'mAP']
        ]
        
        sns.heatmap(metrics_for_heatmap, annot=True, fmt='.1f', cmap='YlGnBu', linewidths=.5)
        plt.title('Perbandingan Metrik Akurasi per Skenario (%)')
        
        # Plot Inference Time - Subplot 2
        plt.subplot(2, 2, 2)
        
        # Buat barplot
        sns.barplot(
            x='Skenario',
            y='Inference Time (ms)',
            hue='Backbone',
            data=success_results,
            palette=['#3498db', '#e74c3c']
        )
        plt.title('Perbandingan Waktu Inferensi (ms)')
        plt.ylabel('Waktu (ms)')
        plt.xticks(rotation=45)
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        
        # Hitung dan Plot FPS - Subplot 3
        plt.subplot(2, 2, 3)
        
        # Tambahkan kolom FPS
        success_results['FPS'] = 1000 / success_results['Inference Time (ms)']
        
        sns.barplot(
            x='Skenario',
            y='FPS',
            hue='Backbone',
            data=success_results,
            palette=['#3498db', '#e74c3c']
        )
        plt.title('Perbandingan FPS (Frame per Second)')
        plt.ylabel('FPS')
        plt.xticks(rotation=45)
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        
        # Plot radar chart - Subplot 4
        ax = plt.subplot(2, 2, 4, polar=True)
        
        # Create radar chart
        _create_radar_chart(
            ax=ax,
            metrics=['Akurasi', 'Precision', 'Recall', 'F1-Score', 'mAP'],
            skenarios=success_results['Skenario'].tolist(),
            data=success_results
        )
        plt.title('Radar Chart Metrik Performa', y=1.1)
        
        plt.tight_layout()
        plt.show()
    
    except Exception as e:
        logger.error(f"‚ùå Error pada fallback visualization: {str(e)}")
        # Jika gagal, coba minimal visualization
        try:
            import matplotlib.pyplot as plt
            
            plt.figure(figsize=(10, 6))
            
            # Simple bar chart of accuracy and inference time
            metrics_chart = success_results.set_index('Skenario')[['Akurasi', 'Inference Time (ms)']]
            metrics_chart.plot(kind='bar', figsize=(10, 6), rot=45)
            
            plt.title('Perbandingan Akurasi dan Waktu Inferensi')
            plt.ylabel('Nilai')
            plt.grid(axis='y', linestyle='--', alpha=0.7)
            plt.tight_layout()
            plt.show()
        except:
            logger.error("‚ùå Tidak dapat membuat visualisasi minimal")

def _create_radar_chart(ax, metrics, skenarios, data):
    """
    Fungsi helper untuk membuat radar chart.
    
    Args:
        ax: Matplotlib axes untuk plot
        metrics: List nama metrik yang akan ditampilkan
        skenarios: List nama skenario
        data: DataFrame dengan data metrics
    """
    # Number of variables
    N = len(metrics)
    
    # Angle for each variable
    angles = np.linspace(0, 2*np.pi, N, endpoint=False).tolist()
    angles += angles[:1]  # Close the loop
    
    # Initialize spider plot
    ax.set_theta_offset(np.pi / 2)
    ax.set_theta_direction(-1)
    
    # Draw one axis per variable and add labels
    plt.xticks(angles[:-1], metrics)
    
    # Draw ylabels
    ax.set_rlabel_position(0)
    plt.yticks([20, 40, 60, 80, 100], ["20%", "40%", "60%", "80%", "100%"], color="grey", size=8)
    plt.ylim(0, 100)
    
    # Plot each scenario
    for skenario in skenarios:
        row = data[data['Skenario'] == skenario]
        if not row.empty:
            values = row[metrics].values[0].tolist()
            values += values[:1]  # Close the loop
            ax.plot(angles, values, linewidth=2, linestyle='solid', label=skenario)
            ax.fill(angles, values, alpha=0.1)
    
    # Add legend
    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))

# ===== 4. UI COMPONENTS =====
# Checkboxes untuk memilih skenario
scenario_checkboxes = []
for scenario in RESEARCH_SCENARIOS:
    checkbox = widgets.Checkbox(
        value=True,
        description=f"{scenario['name']}: {scenario['description']}",
        layout=widgets.Layout(width='auto'),
        style={'description_width': 'initial'}
    )
    scenario_checkboxes.append(checkbox)

# Button untuk menjalankan evaluasi
run_button = widgets.Button(
    description='Jalankan Evaluasi',
    button_style='success',
    icon='play'
)

# Output widget untuk hasil evaluasi
output_area = widgets.Output()

# Handler untuk tombol evaluasi
def on_run_button_clicked(b):
    """Handle klik tombol evaluasi."""
    with output_area:
        clear_output()
        
        # Get selected scenarios
        selected_scenarios = []
        for i, checkbox in enumerate(scenario_checkboxes):
            if checkbox.value:
                selected_scenarios.append(RESEARCH_SCENARIOS[i])
        
        if not selected_scenarios:
            print("‚ö†Ô∏è Pilih minimal satu skenario untuk dievaluasi")
            return
        
        print(f"üîç Menjalankan evaluasi untuk {len(selected_scenarios)} skenario...")
        
        # Disable button during evaluation
        run_button.disabled = True
        run_button.description = "Evaluasi Berjalan..."
        
        try:
            # Run evaluation
            results = run_research_evaluation(selected_scenarios)
            
            # Save results
            if not results.empty:
                current_time = time.strftime("%Y%m%d_%H%M%S")
                os.makedirs('runs/evaluation', exist_ok=True)
                results.to_csv(f'runs/evaluation/results_{current_time}.csv', index=False)
                print(f"‚úÖ Hasil evaluasi disimpan ke runs/evaluation/results_{current_time}.csv")
        except Exception as e:
            print(f"‚ùå Error: {str(e)}")
            import traceback
            traceback.print_exc()
        finally:
            # Re-enable button
            run_button.disabled = False
            run_button.description = "Jalankan Evaluasi"

# Attach handler
run_button.on_click(on_run_button_clicked)

# Tampilkan UI
display(widgets.HTML("<h2>üî¨ Evaluasi Skenario Penelitian</h2>"))
display(widgets.HTML("<p>Pilih skenario yang akan dievaluasi:</p>"))
display(widgets.VBox(scenario_checkboxes))
display(run_button)
display(output_area)

# ===== 5. READ EXISTING RESULTS IF AVAILABLE =====
# Fungsi untuk membaca hasil evaluasi yang sudah ada
def load_existing_results():
    """Load hasil evaluasi yang sudah ada."""
    results_file = Path('runs/evaluation/research_results.csv')
    if results_file.exists():
        try:
            results = pd.read_csv(results_file)
            with output_area:
                print(f"üìã Hasil evaluasi sebelumnya terdeteksi ({len(results)} skenario)")
                display(HTML("<h3>üìä Hasil Evaluasi Sebelumnya</h3>"))
                display(results)
                
                # Add button to visualize existing results
                visualize_button = widgets.Button(
                    description='Visualisasikan Hasil',
                    button_style='info',
                    icon='chart-line'
                )
                
                def on_visualize_clicked(b):
                    visualize_research_results(results)
                
                visualize_button.on_click(on_visualize_clicked)
                display(visualize_button)
                
            return results
        except Exception as e:
            print(f"‚ö†Ô∏è Gagal memuat hasil evaluasi sebelumnya: {str(e)}")
    
    return None

# Load existing results when cell is executed
try:
    existing_results = load_existing_results()
except Exception as e:
    print(f"‚ö†Ô∏è Gagal memuat hasil evaluasi: {str(e)}")