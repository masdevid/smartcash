# Cell 7.1: Inisialisasi dan Import Data Handling (refactored)

# ===== 1. IMPORT DAN SETUP AWAL =====
import gc
import pickle
import sys
import os
import torch
from pathlib import Path
from contextlib import contextmanager

# Pastikan path SmartCash tersedia
if os.getcwd() not in sys.path:
    sys.path.append(os.getcwd())

# Import komponen UI
from smartcash.ui_components.data_components import create_data_handling_ui

# Import handler komponen UI
from smartcash.handlers.ui_handlers.data_handlers import (
    setup_dataset_info_handlers,
    setup_split_dataset_handlers,
    check_data_availability,
    get_dataset_info
)

# Import modul yang diperlukan
from smartcash.utils.logger import get_logger, SmartCashLogger
from smartcash.handlers.data_manager import DataManager
from smartcash.handlers.multilayer_dataset_handler import MultilayerDataManager
from smartcash.utils.enhanced_cache import EnhancedCache
from smartcash.utils.optimized_augmentation import OptimizedAugmentation
from smartcash.handlers.unified_preprocessing_handler import UnifiedPreprocessingHandler

# ===== 2. UTILITY FUNCTIONS =====
@contextmanager
def memory_manager():
    """Context manager untuk mengoptimalkan penggunaan memori."""
    try:
        yield
    finally:
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

# ===== 3. MAIN INITIALIZATION =====
# Set logger
logger = get_logger("data_pipeline", log_to_colab=True, log_to_file=True)

with memory_manager():
    # Load config dari file jika tersedia
    try:
        import yaml
        with open('configs/base_config.yaml', 'r') as f:
            config = yaml.safe_load(f)
    except Exception as e:
        # Fallback ke struktur config minimal jika file tidak ditemukan
        logger.error(f"‚ùå Error loading config: {str(e)}")
        config = {
            'model': {'batch_size': 16, 'workers': 2, 'img_size': [640, 640]},
            'data': {'local': {'train': 'data/train', 'valid': 'data/valid', 'test': 'data/test'}},
            'layers': ['banknote']
        }
    
    # Initialize data manager dan augmentation handler
    data_manager = MultilayerDataManager(
        config=config,
        logger=logger
    )
    
    # Initialize augmentation handler
    aug_manager = OptimizedAugmentation(
        config=config,
        output_dir=None,  # Gunakan direktori default
        logger=logger,
        num_workers=min(2, config.get('model', {}).get('workers', 4))  # Batasi untuk Colab
    )
    
    # Initialize preprocessing handler
    preprocessor = UnifiedPreprocessingHandler(
        config=config,
        logger=logger
    )
    
    # Get dataset information
    active_layers = config.get('layers', ['banknote'])
    logger.info(f"üîç Menggunakan {len(active_layers)} layer aktif: {', '.join(active_layers)}")
    
    # Get dataset statistics
    try:
        stats = data_manager.get_dataset_stats()
        logger.info("\nüìä Statistik Dataset:")
        for split, split_stats in stats.items():
            logger.info(f"{split.capitalize()}:")
            for key, value in split_stats.items():
                if isinstance(value, dict):
                    logger.info(f"  {key}:")
                    for subkey, subvalue in value.items():
                        logger.info(f"    {subkey}: {subvalue}")
                else:
                    logger.info(f"  {key}: {value}")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Gagal mendapatkan statistik dataset: {str(e)}")

    # Simpan objek penting di global untuk diakses dari cell lain
    globals_dict = {
        'data_manager': data_manager,
        'aug_manager': aug_manager,
        'preprocessor': preprocessor,
        'config': config,
        'logger': logger
    }
    
    # Simpan objek global
    with open('data_globals.pkl', 'wb') as f:
        pickle.dump(globals_dict, f)
    
    logger.success("‚ú® Inisialisasi data handling selesai!")

# ===== 4. CREATE AND DISPLAY UI =====
# Buat UI untuk data handling
data_ui = create_data_handling_ui()

# Setup handlers untuk komponen UI
setup_dataset_info_handlers(data_ui['info_components'], data_manager, logger)
setup_split_dataset_handlers(data_ui['split_components'], data_manager, preprocessor, logger)

# Tampilkan UI
display(data_ui['ui'])

# Tampilkan status ketersediaan data
print("üîç Memeriksa ketersediaan data...")
data_available = check_data_availability(data_manager, logger)

# Get dataset info pada startup
with data_ui['info_components']['info_output']:
    get_dataset_info(data_manager, logger)