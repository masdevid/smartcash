{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š Persiapan Dataset SmartCash\n",
    "\n",
    "Notebook ini menjelaskan proses persiapan dataset untuk pelatihan model SmartCash.\n",
    "\n",
    "## ðŸ“‹ Daftar Isi\n",
    "1. [Setup Environment](#setup)\n",
    "2. [Persiapan Dataset](#dataset)\n",
    "3. [Validasi Dataset](#validasi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment <a id='setup'></a>\n",
    "\n",
    "Pertama, kita perlu setup environment dan import library yang diperlukan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Import required modules\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify project structure\n",
    "required_dirs = ['configs', 'data', 'smartcash']\n",
    "missing_dirs = [d for d in required_dirs if not (project_root / d).exists()]\n",
    "\n",
    "if missing_dirs:\n",
    "    raise RuntimeError(\n",
    "        f\"Missing required directories: {missing_dirs}\\n\"\n",
    "        f\"Please run this notebook from the 'notebooks' directory\"\n",
    "    )\n",
    "\n",
    "print(f\"âœ… Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Configuration\n",
    "\n",
    "Load konfigurasi dari file `base_config.yaml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config_path = project_root / 'configs' / 'base_config.yaml'\n",
    "\n",
    "if not config_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Config file not found: {config_path}\\n\"\n",
    "        f\"Please create base_config.yaml in the configs directory\"\n",
    "    )\n",
    "\n",
    "with open(config_path) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"âœ… Loaded config from: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import SmartCash Modules\n",
    "\n",
    "Import modul-modul yang diperlukan dari SmartCash:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from smartcash.utils.logger import SmartCashLogger\n",
    "    from smartcash.handlers.data_handler import DataHandler\n",
    "    from smartcash.handlers.roboflow_handler import RoboflowHandler\n",
    "    from smartcash.utils.preprocessing import ImagePreprocessor\n",
    "    \n",
    "    print(\"âœ… Successfully imported SmartCash modules\")\n",
    "except ImportError as e:\n",
    "    raise ImportError(\n",
    "        f\"Failed to import SmartCash modules: {str(e)}\\n\"\n",
    "        f\"Please make sure all required modules are installed\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Persiapan Dataset <a id='dataset'></a>\n",
    "\n",
    "Setup data handler dan mulai persiapan dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logger\n",
    "logger = SmartCashLogger('dataset_preparation')\n",
    "\n",
    "# Setup data directories\n",
    "data_dir = project_root / 'data'\n",
    "raw_dir = data_dir / 'raw'\n",
    "processed_dir = data_dir / 'processed'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger.info(f\"Data directories setup complete:\\n\"\n",
    "           f\"Raw data: {raw_dir}\\n\"\n",
    "           f\"Processed data: {processed_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load Dataset\n",
    "\n",
    "Pilih sumber dataset (lokal atau Roboflow):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose data source\n",
    "USE_ROBOFLOW = False  # Set True to use Roboflow\n",
    "\n",
    "try:\n",
    "    if USE_ROBOFLOW:\n",
    "        # Check API key\n",
    "        api_key = os.getenv('ROBOFLOW_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\n",
    "                \"ROBOFLOW_API_KEY not found in environment variables\\n\"\n",
    "                \"Please set it in .env file\"\n",
    "            )\n",
    "            \n",
    "        handler = RoboflowHandler(\n",
    "            config_path=str(config_path),\n",
    "            data_dir=str(raw_dir),\n",
    "            api_key=api_key,\n",
    "            logger=logger\n",
    "        )\n",
    "        source_dir = handler.download_dataset()\n",
    "    else:\n",
    "        handler = DataHandler(\n",
    "            config_path=str(config_path),\n",
    "            data_dir=str(raw_dir),\n",
    "            logger=logger\n",
    "        )\n",
    "        source_dir = str(raw_dir)\n",
    "        \n",
    "    logger.success(f\"Dataset loaded from: {source_dir}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load dataset: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Process Dataset\n",
    "\n",
    "Proses dataset untuk setiap split data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = ImagePreprocessor(\n",
    "    config_path=str(config_path),\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# Process each split\n",
    "splits = ['train', 'valid', 'test']\n",
    "\n",
    "for split in splits:\n",
    "    logger.info(f\"Processing {split} split...\")\n",
    "    \n",
    "    try:\n",
    "        # Setup split directories\n",
    "        split_dir = Path(source_dir) / split\n",
    "        out_dir = processed_dir / split\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Get image and label files\n",
    "        image_dir = split_dir / 'images'\n",
    "        label_dir = split_dir / 'labels'\n",
    "        \n",
    "        if not image_dir.exists() or not label_dir.exists():\n",
    "            logger.warning(f\"Skipping {split}: directories not found\")\n",
    "            continue\n",
    "            \n",
    "        image_files = sorted(image_dir.glob('*.jpg'))\n",
    "        label_files = sorted(label_dir.glob('*.txt'))\n",
    "        \n",
    "        # Process each file\n",
    "        for img_path, lbl_path in zip(image_files, label_files):\n",
    "            try:\n",
    "                # Process and save\n",
    "                preprocessor.process_image_and_label(\n",
    "                    image_path=str(img_path),\n",
    "                    label_path=str(lbl_path),\n",
    "                    save_dir=str(out_dir),\n",
    "                    augment=(split == 'train')\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to process {img_path.name}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        logger.success(f\"Completed processing {split} split\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to process {split} split: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validasi Dataset <a id='validasi'></a>\n",
    "\n",
    "Validasi hasil preprocessing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate processed dataset\n",
    "validation_results = {}\n",
    "\n",
    "for split in splits:\n",
    "    logger.info(f\"Validating {split} split...\")\n",
    "    \n",
    "    try:\n",
    "        # Get processed directories\n",
    "        split_dir = processed_dir / split\n",
    "        image_dir = split_dir / 'images'\n",
    "        label_dir = split_dir / 'labels'\n",
    "        \n",
    "        # Check directories exist\n",
    "        if not image_dir.exists() or not label_dir.exists():\n",
    "            raise FileNotFoundError(f\"Missing directories for {split} split\")\n",
    "            \n",
    "        # Count files\n",
    "        image_files = list(image_dir.glob('*.jpg'))\n",
    "        label_files = list(label_dir.glob('*.txt'))\n",
    "        \n",
    "        # Store results\n",
    "        validation_results[split] = {\n",
    "            'images': len(image_files),\n",
    "            'labels': len(label_files),\n",
    "            'status': 'OK' if len(image_files) == len(label_files) else 'ERROR'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        validation_results[split] = {\n",
    "            'images': 0,\n",
    "            'labels': 0,\n",
    "            'status': f'ERROR: {str(e)}'\n",
    "        }\n",
    "\n",
    "# Print summary\n",
    "logger.info(\"\\nDataset Validation Summary:\")\n",
    "for split, result in validation_results.items():\n",
    "    status_color = 'green' if result['status'] == 'OK' else 'red'\n",
    "    logger.info(\n",
    "        f\"{split}: {result['images']} images, {result['labels']} labels \"\n",
    "        f\"[{result['status']}]\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartcash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
