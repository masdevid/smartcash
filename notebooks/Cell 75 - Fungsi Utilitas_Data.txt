# Cell 7.5: Fungsi Utilitas Data

# Pastikan objek global tersedia
try:
    with open('data_globals.pkl', 'rb') as f:
        globals_dict = pickle.load(f)
    
    data_manager = globals_dict['data_manager']
    aug_manager = globals_dict['aug_manager']
    config = globals_dict['config']
    logger = globals_dict['logger']
except Exception as e:
    print(f"❌ Error loading global objects: {str(e)}")
    print("💡 Jalankan Cell 7.1 terlebih dahulu untuk menginisialisasi dataset")

def get_dataloaders(batch_size=None, num_workers=None):
    """
    Dapatkan dataloader untuk training, validation, dan testing dengan pengaturan optimal
    
    Args:
        batch_size: Ukuran batch untuk dataloader (jika None, gunakan default dari config)
        num_workers: Jumlah worker (jika None, menggunakan nilai dari config)
        
    Returns:
        Dictionary berisi dataloaders untuk train, val, dan test
    """
    batch_size = batch_size or config.get('model', {}).get('batch_size', 16)
    num_workers = num_workers or min(2, config.get('model', {}).get('workers', 2))  # Jumlah worker dibatasi untuk Colab
    
    logger.info(f"🔄 Mempersiapkan dataloaders dengan batch size {batch_size}, workers {num_workers}")
    
    # Dapatkan dataloaders
    dataloaders = {}
    try:
        dataloaders['train'] = data_manager.get_dataloader(
            split='train',
            batch_size=batch_size, 
            num_workers=num_workers,
            pin_memory=torch.cuda.is_available()
        )
        
        dataloaders['val'] = data_manager.get_dataloader(
            split='valid',
            batch_size=batch_size,
            num_workers=num_workers,
            pin_memory=torch.cuda.is_available()
        )
        
        dataloaders['test'] = data_manager.get_dataloader(
            split='test',
            batch_size=batch_size,
            num_workers=1,  # Kurangi workers untuk pengujian
            pin_memory=torch.cuda.is_available()
        )
        
        # Log informasi tentang dataloaders
        for name, loader in dataloaders.items():
            if loader and hasattr(loader.dataset, '__len__'):
                logger.info(f"✅ {name.capitalize()} dataloader: {len(loader.dataset)} gambar, {len(loader)} batch")
            else:
                logger.warning(f"⚠️ {name.capitalize()} dataloader: tidak valid atau kosong")
        
        return dataloaders
    except Exception as e:
        logger.error(f"❌ Error creating dataloaders: {str(e)}")
        return {}

def check_data_availability():
    """
    Memeriksa ketersediaan data dan menampilkan statistik
    
    Returns:
        Boolean yang menunjukkan apakah data tersedia untuk training
    """
    try:
        # Dapatkan ukuran dataset
        sizes = {}
        for split in ['train', 'valid', 'test']:
            try:
                dataset = data_manager.get_dataset(split)
                sizes[split] = len(dataset) if dataset else 0
            except Exception as e:
                logger.warning(f"⚠️ Error mendapatkan ukuran dataset {split}: {str(e)}")
                sizes[split] = 0
        
        # Tampilkan informasi
        logger.info("🔍 Memeriksa ketersediaan data...")
        for split, count in sizes.items():
            status = "✅ Tersedia" if count > 0 else "❌ Tidak tersedia"
            logger.info(f"{split.capitalize()}: {count} gambar - {status}")
        
        # Periksa apakah data cukup untuk training
        if sizes.get('train', 0) > 0 and sizes.get('valid', 0) > 0:
            logger.success("✅ Data tersedia untuk training dan validasi")
            return True
        else:
            if sizes.get('train', 0) == 0:
                logger.warning("⚠️ Data training tidak tersedia")
            if sizes.get('valid', 0) == 0:
                logger.warning("⚠️ Data validasi tidak tersedia")
            
            logger.info("💡 Gunakan tab 'Split Dataset' untuk menyiapkan data training dan validasi")
            return False
    except Exception as e:
        logger.error(f"❌ Error saat memeriksa ketersediaan data: {str(e)}")
        return False

def get_class_names():
    """
    Dapatkan nama kelas yang digunakan dalam dataset dari layer config
    
    Returns:
        List nama kelas
    """
    try:
        # Gunakan layer config manager untuk mendapatkan nama kelas
        active_layers = config.get('layers', ['banknote'])
        class_names = []
        
        for layer in active_layers:
            layer_config = data_manager.layer_config.get_layer_config(layer)
            if layer_config and 'classes' in layer_config:
                class_names.extend(layer_config['classes'])
        
        return class_names
    except Exception as e:
        logger.error(f"❌ Error mendapatkan nama kelas: {str(e)}")
        return []

def get_dataset_sizes():
    """
    Dapatkan ukuran dataset untuk setiap split
    
    Returns:
        Dictionary berisi ukuran dataset untuk setiap split
    """
    sizes = {}
    try:
        for split in ['train', 'valid', 'test']:
            try:
                dataset = data_manager.get_dataset(split)
                sizes[split] = len(dataset) if dataset else 0
            except:
                sizes[split] = 0
        return sizes
    except Exception as e:
        logger.error(f"❌ Error mendapatkan ukuran dataset: {str(e)}")
        return {'train': 0, 'valid': 0, 'test': 0}

def visualize_batch(split='train', num_images=4, figsize=(15, 10)):
    """
    Visualisasikan batch dataset untuk debugging dan verifikasi
    
    Args:
        split: Split dataset ('train', 'valid', 'test')
        num_images: Jumlah gambar yang akan divisualisasikan
        figsize: Ukuran figure matplotlib
    """
    try:
        # Dapatkan dataloader dengan batch size = num_images
        loader = data_manager.get_dataloader(
            split=split,
            batch_size=num_images,
            num_workers=0,  # Mengurangi kompleksitas
            shuffle=True    # Acak untuk mendapatkan sampel yang berbeda
        )
        
        # Ambil satu batch
        for images, targets in loader:
            # Konversi ke numpy untuk visualisasi
            if isinstance(images, torch.Tensor):
                images = images.cpu().numpy()
                
                # Transpose dari [B, C, H, W] ke [B, H, W, C]
                images = images.transpose(0, 2, 3, 1)
                
                # Denormalisasi jika perlu
                if images.max() <= 1.0:
                    images = images * 255
                
                images = images.astype(np.uint8)
            
            # Plot images
            fig, axes = plt.subplots(1, min(len(images), num_images), figsize=figsize)
            if min(len(images), num_images) == 1:
                axes = [axes]
                
            for i, ax in enumerate(axes):
                if i < len(images):
                    ax.imshow(images[i])
                    ax.set_title(f"Image {i+1}")
                    ax.axis('off')
            
            plt.tight_layout()
            plt.show()
            
            # Hanya tampilkan batch pertama
            break
    except Exception as e:
        logger.error(f"❌ Error saat visualisasi batch: {str(e)}")
        print(f"Gagal melakukan visualisasi: {str(e)}")

# Tampilkan status ketersediaan data
print("🔍 Memeriksa ketersediaan data...")
data_available = check_data_availability()

# Dapatkan dan tampilkan nama kelas
class_names = get_class_names()
print(f"\n🏷️ Kelas yang tersedia ({len(class_names)}):")
if class_names:
    # Tampilkan dalam format grid
    cols = 3
    class_grid = [class_names[i:i+cols] for i in range(0, len(class_names), cols)]
    for row in class_grid:
        print("  " + "  |  ".join(row))
else:
    print("  Tidak ada kelas yang tersedia")

print("\n✅ Semua fungsi utilitas data telah siap digunakan")
print("💡 Gunakan get_dataloaders() untuk mendapatkan dataloader untuk training")
print("💡 Gunakan visualize_batch() untuk menampilkan contoh gambar dari dataset")