# Cell 8.1: Model initialization - Inisialisasi dan konfigurasi model dengan manajemen memori yang optimal

import os
import torch
import yaml
import gc
import logging
import sys
from pathlib import Path
from datetime import datetime
from IPython.display import display, HTML, clear_output
import ipywidgets as widgets
from tqdm.auto import tqdm
import numpy as np
import matplotlib.pyplot as plt
import traceback
import pickle
from typing import Dict, Any, Optional
from contextlib import contextmanager

# ===== 1. UTILITY FUNCTIONS =====
@contextmanager
def memory_manager():
    """Context manager untuk mengoptimalkan penggunaan memori."""
    try:
        yield
    finally:
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

def setup_gpu() -> Dict[str, Any]:
    """Setup dan dapatkan informasi GPU."""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    gpu_info = {'device': device}
    
    if torch.cuda.is_available():
        gpu_info.update({
            'name': torch.cuda.get_device_name(0),
            'memory_allocated': torch.cuda.memory_allocated(0) / (1024**2),
            'memory_cached': torch.cuda.memory_reserved(0) / (1024**2)
        })
        
        # Optimize CUDA settings
        if hasattr(torch.backends, 'cudnn'):
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.deterministic = False
            
    return gpu_info

def safe_load_pickle(file_path: str, error_msg: str) -> Any:
    """Safely load pickle files with error handling."""
    try:
        with open(file_path, 'rb') as f:
            return pickle.load(f)
    except Exception as e:
        logger.error(f"{error_msg}: {str(e)}")
        raise

# ===== 2. ENVIRONMENT SETUP =====
# Add smartcash to PYTHONPATH
if not os.getcwd() in sys.path:
    sys.path.append(os.getcwd())

# Create necessary directories
os.makedirs("logs", exist_ok=True)

# Setup logger
try:
    from smartcash.utils.logger import get_logger, SmartCashLogger
    logger = get_logger("model_manager", log_to_console=True, log_to_file=True, log_to_colab=True)
    logger.info("✅ Logger initialized successfully")
except Exception as e:
    print(f"⚠️ Failed to import SmartCashLogger: {str(e)}")
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(f"logs/smartcash_{datetime.now().strftime('%Y-%m-%d')}.log"),
            logging.StreamHandler(sys.stdout)
        ]
    )
    from smartcash.utils.simple_logger import SimpleLogger
    logger = SimpleLogger("model_manager")

# ===== 3. MODEL IMPORTS =====
try:
    # Core model imports
    from smartcash.models.backbones.cspdarknet import CSPDarknet
    from smartcash.models.backbones.efficientnet import EfficientNetBackbone
    from smartcash.models.yolov5_model import YOLOv5Model
    from smartcash.handlers.model_handler import ModelHandler

    
    # Utility imports
    from smartcash.utils.early_stopping import EarlyStopping
    from smartcash.utils.model_visualizer import ModelVisualizer
    from smartcash.handlers.checkpoint_handler import CheckpointHandler
    from smartcash.handlers.data_manager import DataManager
    
    logger.success("Model modules imported successfully")
except Exception as e:
    logger.error(f"Failed to import model modules: {str(e)}")
    raise

# ===== 4. MODEL CREATION AND SETUP =====
with memory_manager():
    # Load configurations
    config = safe_load_pickle('config.pkl', "Failed to load config")
    dataloaders = safe_load_pickle('dataloaders.pkl', "Failed to load dataloaders")
    
    try:
        # Initialize handlers
        model_handler = ModelHandler(config=config, logger=logger)
        checkpoint_handler = CheckpointHandler(
            output_dir=config['output_dir'],
            logger=logger
        )
        
        # Create model and move to device
        model = model_handler.create_model(backbone_type=config['model']['backbone'])
        gpu_info = setup_gpu()
        model = model.to(gpu_info['device'])
        
        # Initialize training components
        early_stopping = EarlyStopping(
            patience=config['training']['early_stopping_patience'],
            logger=logger
        )
        model_visualizer = ModelVisualizer(
            output_dir=config['output_dir'],
            logger=logger
        )
        
        # Setup optimizer with gradient clipping
        optimizer = model_handler.get_optimizer(model)
        scheduler = model_handler.get_scheduler(optimizer)
        
        # Save model components
        model_components = {
            'model': model,
            'optimizer': optimizer,
            'scheduler': scheduler,
            'early_stopping': early_stopping,
            'checkpoint_handler': checkpoint_handler,
            'model_visualizer': model_visualizer,
            'device': gpu_info['device']
        }
        
        with open('model_components.pkl', 'wb') as f:
            pickle.dump(model_components, f)
        
        # Log model information
        logger.info("\n=== Model Configuration ===")
        logger.info(f"Backbone: {config['model']['backbone']}")
        logger.info(f"Number of classes: {config['model']['num_classes']}")
        logger.info(f"Image size: {config['model']['img_size']}")
        logger.info(f"Detection layers: {config['layers']}")
        
        # Log GPU information
        if torch.cuda.is_available():
            logger.info("\n=== GPU Status ===")
            logger.info(f"GPU: {gpu_info['name']}")
            logger.info(f"Memory allocated: {gpu_info['memory_allocated']:.2f} MB")
            logger.info(f"Memory cached: {gpu_info['memory_cached']:.2f} MB")
            logger.info("CUDA optimization: Enabled")
        
        logger.success("✨ Model creation and setup completed successfully!")
        
    except Exception as e:
        logger.error(f"Error during model setup: {str(e)}")
        logger.error(traceback.format_exc())
        raise