# SmartCash Training Configuration
# Minimal configuration that matches the actual codebase structure

training:
  # Core training parameters
  epochs: 100
  batch_size: 16
  learning_rate: 0.001
  weight_decay: 0.0005
  
  # Optimizer settings
  optimizer: adam  # Supported: adam, adamw, sgd, rmsprop
  scheduler: cosine  # Supported: cosine, step, plateau, exponential, multistep, cyclic, none
  warmup_epochs: 3  # Optional warmup period
  mixed_precision: true  # Enable mixed precision training
  gradient_clip: 10.0  # Clip gradients to this value, 0 to disable
  
  # Data loading configuration
  data:
    num_workers: 4  # Number of data loading workers
    pin_memory: true  # Pin memory for faster GPU transfer
    persistent_workers: true  # Keep workers alive between epochs
    prefetch_factor: 2  # Number of batches to prefetch per worker
    drop_last: true  # Drop last incomplete batch
  
    mixed_precision: true
  # Loss function configuration
  loss:
    box_weight: 0.05  # Bounding box loss weight
    obj_weight: 1.0    # Objectness loss weight
    cls_weight: 0.5    # Classification loss weight
    focal_loss: false  # Use focal loss if true
    label_smoothing: 0.0  # Label smoothing epsilon
  
  # Early stopping configuration
  early_stopping:
    enabled: true
    patience: 15  # Epochs to wait before stopping
    metric: val_map50  # Metric to monitor (e.g., val_loss, val_map50)
    mode: max  # One of: min, max
    min_delta: 0.001  # Minimum change to qualify as improvement